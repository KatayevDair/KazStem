# KazStem
Датасеты я собирал сам, они приложены к проекту. Можете использовать их для своих задач.(там присутсвуют заголовки с сайта tengrinews.kz)
В качестве проекта для учебной практике мне было предложенно сделать что-то связанное с синтаксом или морфологией казахского языка. По стек и технологиям не было ограничений. Идея мне понравилась. С учетом того, что я не знаю этот язык, значительную часть времени заняло изучение того, как строются слова в казахском языке, об этом поподробнее далее.
# Цель
Сделать стеммер для казахского языка и проверить его эффективность. Добиться улучшения качества прогноза с помощью стемматизации.
# Задачи
<ol>
  <li>Посмотреть, как делают стеммеры для других языков</li>
  <li>Разобраться, как строятся слова в казахском языке</li>
  <li>Собрать данные</li>
  <li>Написать стеммер</li>
  <li>Построить модель, на которой будет проверяется его эффективность</li>
</ol>

# Что такое стеммер и для чего он нужен.
в первую очередь, надо понимать, что компьютер не понимает человеческих слов. Для корректной работы моделей машинного обучения слова надо преобразовать в цифры. Этот процесс называется векторизацией текста. И уже предложения, преобразованные в векторы пропускаются через модель в качестве признаков. Есть много способов преобразования, например такие, как TF-IDF и мешок слов. Первый присваивает словам их важность в контекста предложения и целого корпуса И <strong>чем меньше уникальных слов тем меньше признаков получается после преобразования.</strong>

Но почему меньшее количество признаков - это хорошо? Потому-что если пропустить через трансформатор необработанный корпус, он <strong>обработает одно и тоже слово, но в разных формах по-разному.</strong> Например слово "квартира" может иметь несколько форм: "квартирой"- в творительном падеже, "квартиры" - во множественном числе и так далее. так вот, стеммер приведет все три слова к одной форме - "квартир". Что это? Это корень? Нет, не корень. Это-основа слова, она не всегда совпадает с морфологическим корнем слова. Это может быть нужно, например, для поиска самого популярного слова в запросах поисковика. для некоторых задач форма слова не имеет значения, важен его смысл. Но в тоже время есть примеры, когда разные слова приводятся к одной основе. Например, ТУШить и ТУШа, это называется перестеммирование, или избыточный стемминг.

# Казахская морфология
Вобще, есть несколько видов стеммеров: Алгоритмические, Словарные, Нейросетевые, комбинированные и так далее. Для нейросетевых и словарных стеммеров нужны большие обьемы размеченных данных на казахском, с чем большая проблема(об этом далее). Поэтому <strong>я решил взять за основу алгоритмический</strong>. Мое решение заключается в том, чтобы убрать из слова все словообразующие части слова. В казахском языке это в основном окончания. Очевидно, что от этого пострадают слова, в основе которых стоят слоги идентичные окончаниям, но как мне сказали знающие люди, таких слов немного. Вот список окончаний, суффикосов, приставок и вспомогательных слов, которые я посчитал нужным убрать![image](https://user-images.githubusercontent.com/104565128/173240710-f8942d13-a0d1-4d44-9208-84371c452191.png)

Еще есть такое понятие, как стоп слова. это слова, которые не несут в себе смысла, но увеличивают обьем матрицы признаков. список ниже.![image](https://user-images.githubusercontent.com/104565128/173240929-1d76aa7e-bea6-48b6-bc77-f76f5a7b3916.png)

<strong>ИТОГ:</strong> Стемминг нужен для того, чтобы ученьшить количство уникальных слов, например для того, чтобы избежать переобучения модели. Потому-что модель машинного обучения будет обращать внимание на ненужные детали.

# Данные
С датасетами на казахском языке обстоит большая проблема. Первое, что мне пришло в голову - это спарсить комментарии с какого-нибудь противоречивого видео в соц сетях и разметить через Яндекс.Толоку но 400$ за 10 000 записей это слишком много для проекта по практике. Потом я подумал, что можно спарсить заголовки с новостного сайта и как категорию выбрать категорию новости(спорт, политика, бизнес...). Но я подумал, что проще будет взять и создать две категории - описание новостей и стихи казахских классиков. так я и поступил. Новости я брал с tengrinews.kz. Написал простенький парсер
![image](https://user-images.githubusercontent.com/104565128/173241482-a530d53d-569c-454c-9793-a71815a9df80.png)

Парсил данные патчами, чтобы не перегружать компьютер. Еще я обьеденил две половины корпуса со стихами, чтобы не терять короткие строки и искувственно создать дисбаланс классов, чтобы было, куда расти в плане метрики.

# Стеммер
Его я решил реализовать в виде класса ООП, чтобы в будующем была возможность добавлять функции и в перспективе выпустить в виде библиотеки.![image](https://user-images.githubusercontent.com/104565128/173241605-6fa4c632-fd24-4ecf-8518-89fb60195354.png)

# Модель
В качестве целевой метрики будет правильно выбрать <strong>f1-меру</strong>, потому-что у нас есть явный дисбаланс классов(1:2.5) и именно f1-мера поможет нам отследить то, как наши модели справляются с предсказанием меньшего класса и еще оба класса одинаково важны. Подход с использованием алгоритма линейной регрессии я особо не развивал(апсемплинг, масштабирование, ансамбли) потому-что предварительно знал, насколько высокий результат покажет случайный лес.

</strong>ВАЖНЫЙ МОМЕНТ</strong> Для проверки эффективности стеммера я решил сравнить предсказания лучшего алгоритма на стемматизированных и не стемматизированных данных. Поэтомы, чтобы исключить влияние случайности, нужно в экспериментальном и контрольном блоке везде проставить одинаковое значение random_state в соответсвующих местах.
# Вывод
Вывод смотрите в тетрадке в конце работы.
